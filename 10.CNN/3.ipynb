{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "使用的数据可以从以下网址下载：\n",
    "https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "在我们的设置中，我们：\n",
    "- 创建一个 data/ 文件夹\n",
    "- 在 data/ 里面 创建 train/ and validation/ 子文件夹\n",
    "- 在 train/ 和 validation/ 里面 创建 cats/ and dogs/ 子文件夹\n",
    "- 将猫图片索引0-999放入data/train/cats中\n",
    "- 将猫图片索引1000-1400放在data/validation/cats中\n",
    "- 把狗图片索引12500-13499放在data/train/dogs中\n",
    "- 将狗图片索引13500-13900放在data/validation/dogs中\n",
    "因此，我们每个类有1000个训练范例，每个类有400个验证范例。\n",
    "总之，这是我们的目录结构：\n",
    "```\n",
    "data/\n",
    "    train/\n",
    "        dogs/\n",
    "            dog001.jpg\n",
    "            dog002.jpg\n",
    "            ...\n",
    "        cats/\n",
    "            cat001.jpg\n",
    "            cat002.jpg\n",
    "            ...\n",
    "    validation/\n",
    "        dogs/\n",
    "            dog001.jpg\n",
    "            dog002.jpg\n",
    "            ...\n",
    "        cats/\n",
    "            cat001.jpg\n",
    "            cat002.jpg\n",
    "            ...\n",
    "```\n",
    "'''\n",
    "\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "\n",
    "# 我们的图像的尺寸。\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "# 构建VGG16网络\n",
    "\n",
    "base_model = applications.VGG16(weights='imagenet',\n",
    "                                include_top=False,\n",
    "                                input_shape=(img_width, img_height, 3))\n",
    "print('Model loaded.')\n",
    "\n",
    "# 在卷积模型的基础上建立分类器模型\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 注意，为了成功地进行微调，有必要从一个完全训练的分类器开始，包括顶级分类器\n",
    "\n",
    "# 在基础卷积上加上模型\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(top_model)\n",
    "# 设置前25层（直到最后一个conv块）\n",
    "# 不可训练（重量不更新）\n",
    "for layer in model.layers[:25]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# 用SGD/momentum优化器和非常慢的学习速度编译模型。\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 准备数据扩充配置\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                    target_size=(img_height,\n",
    "                                                                 img_width),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "# 微调模型\n",
    "model.fit_generator(train_generator,\n",
    "                    samples_per_epoch=nb_train_samples,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=validation_generator,\n",
    "                    nb_val_samples=nb_validation_samples)\n",
    "model.save_weights('try_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
