{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda:0\n",
      "GeForce GTX 960M\n",
      "tensor([[0.3231, 0.6489, 0.9500],\n",
      "        [0.6285, 0.6449, 0.7881],\n",
      "        [0.1745, 0.1083, 0.3599]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "flag = torch.cuda.is_available()\n",
    "print(flag)\n",
    "\n",
    "ngpu= 1\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.rand(3,3).cuda()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:CPU:0 /device:CPU:0\n",
      "/device:GPU:0 /device:GPU:0\n",
      "warmup: 0.009669332999999725 0.00834711100000085\n",
      "run time: 0.0072817770000010995 0.008067111000000793\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import timeit\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    cpu_a = tf.random.normal([10000, 1000])\n",
    "    cpu_b = tf.random.normal([1000, 2000])\n",
    "    print(cpu_a.device, cpu_b.device)\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    gpu_a = tf.random.normal([10000, 1000])\n",
    "    gpu_b = tf.random.normal([1000, 2000])\n",
    "    print(gpu_a.device, gpu_b.device)\n",
    "\n",
    "def cpu_run():\n",
    "    with tf.device('/cpu:0'):\n",
    "        c = tf.matmul(cpu_a, cpu_b)\n",
    "    return c\n",
    "\n",
    "def gpu_run():\n",
    "    with tf.device('/gpu:0'):\n",
    "        c = tf.matmul(gpu_a, gpu_b)\n",
    "    return c\n",
    "\n",
    "# warm up\n",
    "cpu_time = timeit.timeit(cpu_run, number=10)\n",
    "gpu_time = timeit.timeit(gpu_run, number=10)\n",
    "print('warmup:', cpu_time, gpu_time)\n",
    "\n",
    "cpu_time = timeit.timeit(cpu_run, number=10)\n",
    "gpu_time = timeit.timeit(gpu_run, number=10)\n",
    "print('run time:', cpu_time, gpu_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1405.2429  1441.7413  1364.38    ... 1480.2251  1279.0061  1620.0938 ]\n",
      " [1232.6589  1344.4458  1169.7095  ... 1205.1284  1040.5566  1421.967  ]\n",
      " [1209.3164  1180.3206  1158.1396  ... 1200.0344  1014.03217 1222.5107 ]\n",
      " ...\n",
      " [1298.9648  1262.9236  1205.6918  ... 1396.479   1090.7253  1437.241  ]\n",
      " [1118.2473  1209.0151  1077.7229  ... 1180.7025  1076.4694  1139.742  ]\n",
      " [1200.8866  1297.2266  1260.01    ... 1289.4297  1165.2448  1433.4183 ]]\n",
      "4.052607536315918 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "begin = time.time()\n",
    "with tf.device('/gpu:0'):\n",
    "    rand_t = tf.random_uniform([50,50],0,10,dtype=tf.float32,seed=0)\n",
    "    a = tf.Variable(rand_t)\n",
    "    b = tf.Variable(rand_t)\n",
    "    c = tf.matmul(a,b)\n",
    "    init = tf.global_variables_initializer()\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True)) #强制使用GPU\n",
    "sess.run(init)\n",
    "print(sess.run(c))\n",
    "end = time.time()\n",
    "print(end-begin,'s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
